# Chatbot_CV
A chatbot that asks and answers questions about information from a user's CV

## ğŸ“‹ Overview

This project implements a full-stack application featuring:

- A FastAPI backend with LangGraph for conversational AI
- A Streamlit ui for chat interface
- Vector storage using Qdrant for semantic search capabilities
- Docker for containerization and easy deployment

## âš™ï¸ Components

### Backend

- **FastAPI Application**: REST API with structured routes
- **LangGraph Integration**: Manages conversation flow and agent interactions
- **OpenAI Integration**: Leverages OpenAI for natural language processing
- **Vector Storage**: Uses Qdrant for semantic search and retrieval

### Frontend

- **Streamlit ui**: The user interface is built with Streamlit, providing an intuitive and interactive experience directly in the browser.

## ğŸš€ Getting Started

### Prerequisites

- Docker and Docker Compose
-  OpenAI API key
- Qdrant instance (self-hosted or cloud)

### Installation

1. Clone the repository:
   ```bash
   git clone <repository-url>
   cd Chatbot_RAG
   ```

2. Set up environment variables:
   ```bash
   cp .env.template .env
   ```

   Edit the `.env` file with your API keys and configuration

3. Start the application using docker compose:
    ```
    docker compose up --build
    ```
## ğŸ—ï¸ Project Structure
    ```
    â”œâ”€â”€ chatbot                         # Backend FastAPI application
    â”‚   â”œâ”€â”€ api/                        # API routes and helpers
    â”‚   â”œâ”€â”€ app/                        # Core app services and configs
    â”‚   â”œâ”€â”€ Dockerfile                  # Dockerfile for backend container
    â”‚   â”œâ”€â”€ domain/                     # Core entities and business logic
    â”‚   â”œâ”€â”€ infrastructure/             # Infrastructure components
    â”‚   â”œâ”€â”€ main.py                     # Entry point for FastAPI service
    â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies for backend
    â”‚   â”œâ”€â”€ shared/                     # Shared utilities and configs
    â”‚   â””â”€â”€ tests/                      # integration tests
    â”œâ”€â”€ data                            # Data storage
    â”‚   â”œâ”€â”€ convert/                    # Data conversion scripts
    â”‚   â””â”€â”€ raw/                        # Unprocessed data files
    â”œâ”€â”€ docker-compose.yml              # Docker Compose config for orchestrating services
    â”œâ”€â”€ frontend                        # Frontend application
    â”‚   â”œâ”€â”€ app.py                      # Main script for frontend service
    â”‚   â”œâ”€â”€ Dockerfile                  # Dockerfile for frontend container
    â”‚   â””â”€â”€ requirements.txt            # Python dependencies for frontend
    â”œâ”€â”€ README.md                       # Project documentation
    â””â”€â”€ test.ipynb                      # Jupyter notebook for testing
    ```

## ğŸ’» Usage

Once the application is running:

1. Access the frontend at: http://localhost:8501
2. The backend API is available at: http://localhost:5000

## ğŸ”§ Dependencies

### Backend
- FastAPI
- LangGraph
- LangChain
- Uvicorn
- Qdrant Client
- OpenAI

### Frontend
- Streamlit
